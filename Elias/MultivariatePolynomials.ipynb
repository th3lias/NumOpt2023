{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad, hessian\n",
    "from Functions import MultivariatePolynomials as M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = M().f_1\n",
    "f2 = M().f_2\n",
    "f3 = M().f_3\n",
    "f4 = M().f_4\n",
    "f5 = M().f_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking(f, x, deriv, p, alpha, c=0.1, rho=0.9):\n",
    "    while f(x+alpha*p) > f(x) + c*alpha*deriv.T.dot(p):\n",
    "        alpha = rho*alpha\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_method(f, x0, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Newton's method for finding the minimum of a function f.\n",
    "    :param f: function to minimize\n",
    "    :param x0: initial point\n",
    "    :param eps: tolerance\n",
    "    :return: minimum point, minimum value\n",
    "    \"\"\"\n",
    "    x = x0\n",
    "    grad_fn = grad(f)\n",
    "    hess_fn = hessian(f)\n",
    "    k = 0\n",
    "    while True:\n",
    "        deriv = grad_fn(x)\n",
    "        hess = hess_fn(x)\n",
    "        if np.linalg.norm(deriv) < eps:\n",
    "            break\n",
    "        p = np.linalg.solve(hess, -deriv)\n",
    "        alpha = backtracking(f, x, deriv, p, 0.9)\n",
    "        x = x + alpha * p\n",
    "        k += 1\n",
    "        if k > 10_000:\n",
    "            print(f\"No convergence after {k} iterations.\")\n",
    "            break\n",
    "    return x, f(x), k, deriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum point: [-0.27967741 -0.13702661]\n",
      "Minimum value: 1.2442950993354858\n",
      "Number of iterations: 8\n",
      "|x-x_hat|: 5.662705073758775e-07\n",
      "Derivative at minimum point: [1.62316821e-07 1.51753255e-07]\n",
      "Grad norm: 2.2220666198131606e-07\n"
     ]
    }
   ],
   "source": [
    "x, f_x, k, deriv = newton_method(f1, x0)\n",
    "x_hat = np.array([-0.279677, -0.137027])\n",
    "print(f\"Minimum point: {x}\")\n",
    "print(f\"Minimum value: {f_x}\")\n",
    "print(f\"Number of iterations: {k}\")\n",
    "print(f\"|x-x_hat|: {np.linalg.norm(x-x_hat)}\")\n",
    "print(f\"Derivative at minimum point: {deriv}\")\n",
    "print(f\"Grad norm: {np.linalg.norm(deriv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum point: [0.49999993 0.        ]\n",
      "Minimum value: 4.937350298294505e-15\n",
      "Number of iterations: 9\n",
      "|x-x_hat|: 7.02662789064945e-08\n",
      "Derivative at minimum point: [-1.40532573e-07  0.00000000e+00]\n",
      "Grad norm: 1.4053257262504013e-07\n"
     ]
    }
   ],
   "source": [
    "x, f_x, k, deriv = newton_method(f2, x0)\n",
    "x_hat = np.array([0.5, 0.0])\n",
    "print(f\"Minimum point: {x}\")\n",
    "print(f\"Minimum value: {f_x}\")\n",
    "print(f\"Number of iterations: {k}\")\n",
    "print(f\"|x-x_hat|: {np.linalg.norm(x-x_hat)}\")\n",
    "print(f\"Derivative at minimum point: {deriv}\")\n",
    "print(f\"Grad norm: {np.linalg.norm(deriv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum point: [-0.9999999  0.       ]\n",
      "Minimum value: 1.0000000011677344e-14\n",
      "Number of iterations: 7\n",
      "|x-x_hat|: 1.0000000005838672e-07\n",
      "Derivative at minimum point: [2.e-07 8.e-07]\n",
      "Grad norm: 8.246211256050013e-07\n"
     ]
    }
   ],
   "source": [
    "x, f_x, k, deriv = newton_method(f3, x0)\n",
    "x_hat = np.array([-1.0, 0.0])\n",
    "print(f\"Minimum point: {x}\")\n",
    "print(f\"Minimum value: {f_x}\")\n",
    "print(f\"Number of iterations: {k}\")\n",
    "print(f\"|x-x_hat|: {np.linalg.norm(x-x_hat)}\")\n",
    "print(f\"Derivative at minimum point: {deriv}\")\n",
    "print(f\"Grad norm: {np.linalg.norm(deriv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum point: [0.49109169 0.49818231]\n",
      "Minimum value: 0.24466243778494925\n",
      "Number of iterations: 17\n",
      "|x-x_hat|: 4.3707300756653236e-07\n",
      "Derivative at minimum point: [1.18502744e-07 8.25899983e-08]\n",
      "Grad norm: 1.4444378895234142e-07\n"
     ]
    }
   ],
   "source": [
    "x, f_x, k, deriv = newton_method(f4, x0)\n",
    "x_hat = np.array([0.491092, 0.498182])\n",
    "print(f\"Minimum point: {x}\")\n",
    "print(f\"Minimum value: {f_x}\")\n",
    "print(f\"Number of iterations: {k}\")\n",
    "print(f\"|x-x_hat|: {np.linalg.norm(x-x_hat)}\")\n",
    "print(f\"Derivative at minimum point: {deriv}\")\n",
    "print(f\"Grad norm: {np.linalg.norm(deriv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum point: [0.04288348 0.86998149]\n",
      "Minimum value: 1.6666452245675156\n",
      "Number of iterations: 7\n",
      "|x-x_hat|: 1.5647249893075767e-06\n",
      "Derivative at minimum point: [-1.33335583e-07 -3.49678128e-07]\n",
      "Grad norm: 3.742367842885325e-07\n"
     ]
    }
   ],
   "source": [
    "x, f_x, k, deriv = newton_method(f5, x0)\n",
    "x_hat = np.array([0.042883, 0.86998])\n",
    "print(f\"Minimum point: {x}\")\n",
    "print(f\"Minimum value: {f_x}\")\n",
    "print(f\"Number of iterations: {k}\")\n",
    "print(f\"|x-x_hat|: {np.linalg.norm(x-x_hat)}\")\n",
    "print(f\"Derivative at minimum point: {deriv}\")\n",
    "print(f\"Grad norm: {np.linalg.norm(deriv)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
